{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "MMA/GMMA 2022 869 Individual Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsaripalli/airbnbteamproject/blob/main/Shirley_Hu-MMA_GMMA_2022_869_Individual_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKmorPdno_n_"
      },
      "source": [
        "# MMA/GMMA/MMAI 869: Individual Assignment\n",
        "\n",
        "Version 1: Updated September 27, 2021\n",
        "\n",
        "<font color='red'>\\# TODO: fill in the below</font>\n",
        "\n",
        "- [Shirley, Hu]\n",
        "- [20191894]\n",
        "- [Section 1]\n",
        "- [Poor Dad, Rich Dad]\n",
        "- [2021-11-15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emfFtv4aHBI1"
      },
      "source": [
        "# Assignment Instructions\n",
        "\n",
        "This assignment contains four questions. The questions are fully contained in this Google Colab Notebook. \n",
        "\n",
        "You are to make a copy of this Notebook and edit the copy to provide your answers. You are to complete the assignment entirely within Google Colab. Why?\n",
        "\n",
        "- It gives you practice using cloud-based interactive notebook environments (which is a popular workflow)\n",
        "- It is easier for you to manage the environment (e.g., installing packages, etc.)\n",
        "- Google Colab has nice, beefy machines, so you don't have to worry about running out of memory on your local computer.\n",
        "- It will be easier for the TA to help you debug your code if you need help\n",
        "- It will be easier for the TA to mark/run your code\n",
        "\n",
        "Some parts of this assigment require you to write code. Use Python or R. For Python, you may use standard Python libraries, including `scikit-learn`, `pandas`, `numpy`, and `scipy`. For R, you may use `dplyr`, `caret`, `ggplot2`, `rpart` and other standard libraries.\n",
        "\n",
        "Some parts of this assignment require text responses. In these cases, type your response in the Notebook cell indicated. Use English. Use proper grammar, spelling, and punctuation. Be professional and clear. Be complete, but not overly-verbose. Feel free to use [Markdown syntax](https://www.markdownguide.org/basic-syntax/) to format your answer (i.e., add bold, italics, lists, tables).\n",
        "\n",
        "## What to Submit to the Course Portal\n",
        "\n",
        "- Export your completed Notebook as a PDF file by clicking File->Print->Save as PDF.\n",
        "- Please do not submit the Notebook file (`.ipynb`) to the course portal. \n",
        "- Please submit the PDF export of the Notebook. \n",
        "   - Please name the PDF file `2022_869_FirstnameLastName.pdf`\n",
        "      - E.g., `2022_869_StephenThomas.pdf`\n",
        "   - Please make sure you have run all the cells so we can see the output!\n",
        "   - Best practice: Before exporting to PDF click Runtime->Restart and run all.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZFTCX4DqmRO"
      },
      "source": [
        "# Preliminaries: Inspect and Set up environment\n",
        "\n",
        "No action is required on your part in this section. These cells print out helpful information about the environment, just in case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj34Jz-Do_oK"
      },
      "source": [
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqQ_XOKyXTS6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c08089bc-1f70-474d-d428-cb706af57f55"
      },
      "source": [
        "print(datetime.datetime.now())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-08 12:40:41.157837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfOMt1lErLhZ",
        "outputId": "32978a1c-80f5-4f47-e308-e1097f9d797a"
      },
      "source": [
        "!which python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/bin/python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aub2w1-arM5K",
        "outputId": "f00c7a88-117f-4e5d-841d-bdec67a7847d"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9Y_n_8UrO9i",
        "outputId": "47f43ec0-1929-4cac-bb1f-2f890e792b9b"
      },
      "source": [
        "!echo $PYTHONPATH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/env/python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qyD7Jl0Gw1E"
      },
      "source": [
        "# TODO: install any packages you need to here. For example:\n",
        "#pip install unidecode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLlBjIyS2o54"
      },
      "source": [
        "# Question 1: Uncle Steve's Diamonds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj1NSQelo_oN"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "You work at a local jewelry store named *Uncle Steve's Diamonds*. You started as a janitor, but you’ve recently been promoted to senior data analyst! Congratulations.\n",
        "\n",
        "Uncle Steve, the store's owner, needs to better understand the store's customers. In particular, he wants to know what kind of customers shop at the store. He wants to know the main types of *customer personas*. Once he knows these, he will contemplate ways to better market to each persona, better satisfy each persona, better cater to each persona, increase the loyalty of each persona, etc. But first, he must know the personas.\n",
        "\n",
        "You want to help Uncle Steve. Using sneaky magic (and the help of Environics), you've collected four useful features for a subset of the customers: age, income, spending score (i.e., a score based on how much they’ve spent at the store in total), and savings (i.e., how much money they have in their personal bank account). \n",
        "\n",
        "**Your tasks**\n",
        "\n",
        "1. Pick a clustering algorithm (the [`sklearn.cluster`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.cluster) module has many good choices, including [`KMeans`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans), [`DBSCAN`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN), and [`AgglomerativeClustering`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering) (aka Hierarchical)). (Note that another popular implementation of the hierarchical algorithm can be found in SciPy's [`scipy.cluster.hierarchy.linkage`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html).) Don't spend a lot of time thinking about which algorithm to choose - just pick one. Cluster the customers as best as you can, within reason. That is, try different feature preprocessing steps, hyperparameter values, and/or distance metrics. You don't need to try every posssible combination, but try a few at least. Measure how good each  model configuration is by calculating an internal validation metric (e.g., [`calinski_harabasz_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.calinski_harabasz_score.html) or [`silhouette_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score)).\n",
        "2. You have some doubts - you're not sure if the algorithm you chose in part 1 is the best algorithm for this dataset/problem. Neither is Uncle Steve. So, choose a different algorithm (any!) and do it all again.\n",
        "3. Which clustering algorithm is \"better\" in this case? Think about charateristics of the algorithm like quality of results, ease of use, speed, interpretability, etc. Choose a \"winner\" and justify to Uncle Steve.\n",
        "4. Interpret the clusters of the winning model. That is, describe, in words, a *persona* that accurately depicts each cluster. Use statistics (e.g., cluster means/distributions), examples (e.g., exemplar instances from each cluster), and/or visualizations (e.g., relative importance plots, snakeplots) to get started. Human judgement and creativity will be necessary. This is where it all comes together. Be descripive and *help Uncle Steve understand his customers better*. Please!\n",
        "\n",
        "**Marking**\n",
        "\n",
        "The coding parts (i.e., 1 and 2) will be marked based on:\n",
        "\n",
        "- *Correctness*. Code clearly and fully performs the task specified.\n",
        "- *Reproducibility*. Code is fully reproducible. I.e., you (and I) are able to run this Notebook again and again, from top to bottom, and get the same results each time.\n",
        "- *Style*. Code is organized. All parts commented with clear reasoning and rationale. No old code laying around. Code easy to follow.\n",
        "\n",
        "\n",
        "Parts 3 and 4 will be marked on:\n",
        "\n",
        "- *Quality*. Response is well-justified and convincing. Responses uses facts and data where possible.\n",
        "- *Style*. Response uses proper grammar, spelling, and punctuation. Response is clear and professional. Response is complete, but not overly-verbose. Response follows length guidelines.\n",
        "\n",
        "\n",
        "**Tips**\n",
        "\n",
        "- Since clustering is an unsupervised ML technique, you don't need to split the data into training/validation/test or anything like that. Phew!\n",
        "- On the flip side, since clustering is unsupervised, you will never know the \"true\" clusters, and so you will never know if a given algorithm is \"correct.\" There really is no notion of \"correctness\" - only \"usefullness.\"\n",
        "- Many online clustering tutorials (including some from Uncle Steve) create flashy visualizations of the clusters by plotting the instances on a 2-D graph and coloring each point by the cluster ID. This is really nice and all, but it can only work if your dataset only has exactly two features - no more, no less. This dataset has more than two features, so you cannot use this technique. (But that's OK - you don't need to use this technique.) \n",
        "- Must you use all four features in the clustering? Not necessarily, no. But \"throwing away\" quality data, for no reason, is unlikely to improve a model.\n",
        "- Some people have success applying a dimensionality reduction technique (like [`sklearn.decomposition.PCA`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)) to the features before clustering. You may do this if you wish, although it may not be as helpful in this case because there are only four features to begin with.\n",
        "- If you apply a transformation (e.g., [`MinMaxScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) or [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler)) to the features before clustering, you may have difficulty interpretting the means of the clusters (e.g., what is a mean Age of 0.2234??). There are two options to fix this: first, you can always reverse a transformation with the `inverse_transform` method. Second, you can just use the original dataset (i.e., before any prepropoceesing) during the interpreation step.\n",
        "- You cannot change the distance metric for K-Means. (This is for theoretical reasons: K-Means only works/makes sense with Euclidean distance.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yww0-vtpOw7z"
      },
      "source": [
        "## 1.0: Load data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVWx2c-DhQYo",
        "outputId": "952618fe-1e32-4cbc-b98a-b72110b42373"
      },
      "source": [
        "# DO NOT MODIFY THIS CELL\n",
        "df1 = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1thHDCwQK3GijytoSSZNekAsItN_FGHtm\")\n",
        "df1.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 505 entries, 0 to 504\n",
            "Data columns (total 4 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Age            505 non-null    int64  \n",
            " 1   Income         505 non-null    int64  \n",
            " 2   SpendingScore  505 non-null    float64\n",
            " 3   Savings        505 non-null    float64\n",
            "dtypes: float64(2), int64(2)\n",
            "memory usage: 15.9 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R04NzckZKbG2"
      },
      "source": [
        "## 1.1: Clustering Algorithm #1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qeavkicwo_oN"
      },
      "source": [
        "# TODO: delete this comment and insert code here. Feel free to add more code cells as appropriate."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihVtYBWg1NM6"
      },
      "source": [
        "## 1.2: Clustering Algorithm #2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu2xugQj1Mci"
      },
      "source": [
        "# TODO: delete this comment and insert code here. Feel free to add more code cells as appropriate."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ySJIgNr1Sfy"
      },
      "source": [
        "## 1.3 Model Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwQembOT1L6U"
      },
      "source": [
        "TODO: Delete this text and insert your answer here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP2EAnCJ1Xta"
      },
      "source": [
        "## 1.4 Personas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVewu2TZ1XhK"
      },
      "source": [
        "TODO: Delete this text and insert your answer here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYwuYIgczYSv"
      },
      "source": [
        "# Question 2: Uncle Steve's Fine Foods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oCr-mTfNG-H"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "Uncle Steve runs a small, local grocery store in Ontario. The store sells all the normal food staples (e.g., bread, milk, cheese, eggs, more cheese, fruits, vegatables, meat, fish, waffles, ice cream, pasta, cereals, drinks), personal care products (e.g., toothpaste, shampoo, hair goo), medicine, and cakes. There's even a little section with flowers and greeting cards! Normal people shop here, and buy normal things in the normal way.\n",
        "\n",
        "Business is OK but Uncle Steve wants more. He's thus on the hunt for customer insights. Given your success at the jewelry store, he has asked you to help him out. \n",
        "\n",
        "He has given you a few years' worth of customer transactions, i.e., sets of items that customers have purchased. You have applied an association rules learning algorithm (like Apriori) to the data, and the algorithm has generated a large set of association rules of the form `{X} -> {Y}`, where `{X}` and `{Y}` are item-sets.\n",
        "\n",
        "Now comes a thought experiment. For each of the following scenarios, state what one of the discovered association rules might be that would meet the stated condition. (Just make up the rule, using your human experience and intuition.) Also, describe whether and why each rule would be considered interesting or uninteresting for Uncle Steve (i.e., is this insight new to him? Would he be able to use it somehow?).\n",
        "\n",
        "Keep each answer to 600 characters or less (including spaces).\n",
        "\n",
        "To get those brain juices going, an example condition and answer is provided below:\n",
        "\n",
        "> Condition: A rule that has high support.\n",
        "\n",
        "> Answer: The rule `{milk} -> {bread}` would have high support, since milk and bread are household staples and a high percentage of transactions would include both `{milk}` and `{bread}`. Uncle Steve would likely not find this rule interesting, because these items are so common, he would have surely already noticed that so many transactions contain them.\n",
        "\n",
        "**Marking**\n",
        "\n",
        "Your responses will be marked as follows:\n",
        "\n",
        "- *Correctness*. Rule meets the specificed condition, and seems plausible in an Ontario grocery store.\n",
        "- *Justification of interestness*. Response clearly describes whether and why the rule would be considered interesting to Uncle Steve.\n",
        "\n",
        "**Tips**\n",
        "\n",
        "- There is no actual data for this question. This question is just a thought exercise. You need to use your intuition, creatitivty, and understanding of the real world. I assume you are familiar with what happens inside of normal grocery stores. We are not using actual data and you do not need to create/generate/find any data. I repeat: there is no data for this question.\n",
        "- The reason this question is having you do a thought experiment, rather than writing and running code to find actual association rules on an actual dataset, is because writing code to find association rules is actually pretty easy. But using your brain to come up with rules that meet certain criteria, on the other hand, is a true test of whether you understand how the algorithm works, what support and confidence mean, and the applicability of rules. The question uses the grocery store context because most, if not all, students should be familiar from personal experience.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YQsOb6CzYVq"
      },
      "source": [
        "## 2.1: A rule that might have high support and high confidence. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzXu1IvK-MEg"
      },
      "source": [
        "TODO: Delete this text and insert your answer here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNIrAgJk-L4l"
      },
      "source": [
        "## 2.2: A rule that might have reasonably high support but low confidence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svdzYW3S-LvF"
      },
      "source": [
        "TODO: Delete this text and insert your answer here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loe--LMz-Ll8"
      },
      "source": [
        "## 2.3: A rule that might have low support and low confidence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdyOB5fe-Zgy"
      },
      "source": [
        "TODO: Delete this text and insert your answer here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St2eI3We-ZYs"
      },
      "source": [
        "## 2.4: A rule that might have low support and high confidence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcdZc-B1-fE7"
      },
      "source": [
        "TODO: Delete this text and insert your answer here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_IHoz7f2yIV"
      },
      "source": [
        "# Question 3: Uncle Steve's Credit Union"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhERdkp_zYBY"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "Uncle Steve has recently opened a new credit union in Kingston, named *Uncle Steve's Credit Union*. He plans to disrupt the local market by instaneously providing credit to customers.\n",
        "\n",
        "The first step in Uncle Steve's master plan is to create a model to predict whether an application has *good risk* or *bad risk*. He has outsourced the creation of this model to you.\n",
        "\n",
        "You are to create a classification model to predict whether a loan applicant has good risk or bad risk. You will use data  that Uncle Steve bought from another credit union (somewhere in Europe, he thinks?) that has around 6000 instances and a number of demographics features (e.g., `Sex`, `DateOfBirth`, `Married`), loan details (e.g., `Amount`, `Purpose`), credit history (e.g., number of loans), as well as an indicator (called `BadCredit` in the dataset) as to whether that person was a bad risk.\n",
        "\n",
        "\n",
        "**Your tasks**\n",
        "\n",
        "To examine the effects of the various ML stages, you are to create the model several times, each time adding more sophistication, and measuring how much the model improved (or not). In particular, you will:\n",
        "\n",
        "0. Split the data in training and testing. Don't touch the testing data again, for any reason, until step 5. We are pretending that the testing data is \"future, unseen data that our model won't see until production.\" I'm serious, don't touch it. I'm watching you!\n",
        "1. Build a baseline model - no feature engineering, no feature selection, no hyperparameter tuning (just use the default settings), nothing fancy. (You may need to do some basic feature transformations, e.g., encoding of categorical features, or dropping of features you do not think will help or do not want to deal with yet.) Measure the performance using K-fold cross validation (recommended: [`sklearn.model_selection.cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)) on the training data. Use at least 5 folds, but more are better. Choose a [`scoring` parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) (i.e., classification metric) that you feel is appropriate for this task. Don't use accuracy. Print the mean score of your model.\n",
        "2. Add a bit of feature engineering. The [`sklearn.preprocessing`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) module contains many useful transformations. Engineer at least three new features. They don't need to be especially ground-breaking or complicated. Dimensionality reduction techniques like [`sklearn.decomposition.PCA`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) are fair game but not required. (If you do use dimensionality reduction techniques, it would only count as \"one\" new feature for the purposes of this assignment, even though I realize that PCA creates many new \"features\" (i.e., principal componentns).) Re-train your baseline model. Measure performance. Compare to step 1.\n",
        "3. Add feature selection. The [`sklearn.feature_selection`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has some algorithms for you to choose from. After selecting features, re-train your model, measure performance, and compare to step 2.\n",
        "4. Add hyperparameter tuning. Make reasonable choices and try to find the best (or at least, better) hyperparameters for your estimator and/or transformers. It's probably a good idea to stop using `cross_val_score` at this point and start using [`sklearn.model_selection.GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) as it is specifically built for this purpose and is more convienient to use. Measure performance and compare to step 3.\n",
        "5. Finally, estimate how well your model will work in production. Use the testing data (our \"future, unseen data\") from step 0. Transform the data as appropriate (easy if you've built a pipeline, a little more difficult if not), use the model from step 4 to get predictions, and measure the performance. How well did we do? \n",
        "\n",
        "\n",
        "**Marking**\n",
        "\n",
        "Each part will be marked for:\n",
        "- *Correctness*. Code clearly and fully performs the task specified.\n",
        "- *Reproducibility*. Code is fully reproducible. I.e., you (and I) should be able to run this Notebook again and again, from top to bottom, and get the same results each and every time.\n",
        "- *Style*. Code is organized. All parts commented with clear reasoning and rationale. No old code laying around. Code easy to follow. \n",
        "\n",
        "\n",
        "**Tips**\n",
        "- The origins of the dataset are a bit of a mystery. Assume the data set is recent (circa 2021) and up-to-date. Assume that column names are correct and accurate.\n",
        "- You don't need to experiment with more than one algorithm/estimator. Just choose one (e.g., [`sklearn.tree.DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), [`sklearn.ensemble.RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier), [`sklearn.linear_model.LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression), [`sklearn.svm.LinearSVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC), whatever) and stick with it for this question. \n",
        "- There is no minimum accuracy/precision/recall for this question. I.e., your mark will not be based on how good your model is. Rather, you mark will be based on good your process is.\n",
        "- Watch out for data leakage and overfitting. In particular, be sure to `fit()` any estimators and transformers (collectively, *objects*) only to the training data, and then use the objects' `transform()` methods on both the training and testing data. [Data School](https://www.youtube.com/c/dataschool/featured) has a [helpful video](https://www.youtube.com/watch?v=g2XsZdwbCCs) about this. [Pipelines](https://www.youtube.com/watch?v=1Y6O9nCo0-I) are very helpful here and make your code shorter and more robust (at the expense of making it harder to understand), and I recommend using them, but they are not required for this assignment.\n",
        "- Create as many code cells as you need. In general, each cell should do one \"thing.\"\n",
        "-\tDon't print large volumes of output. E.g., don't do: `df.head(100)`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqm_REd4oouz"
      },
      "source": [
        "## 3.0: Load data and split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6b_BM0Nz9sF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa77f2e3-c6a2-4b80-bfcf-75fb641234ea"
      },
      "source": [
        "# DO NOT MODIFY THIS CELL\n",
        "\n",
        "# First, we'll read the provided labeled training data\n",
        "df3 = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1wOhyCnvGeY4jplxI8lZ-bbYN3zLtickf\")\n",
        "df3.info()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df3.drop('BadCredit', axis=1) #.select_dtypes(['number'])\n",
        "y = df3['BadCredit']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6000 entries, 0 to 5999\n",
            "Data columns (total 17 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   UserID             6000 non-null   object\n",
            " 1   Sex                6000 non-null   object\n",
            " 2   PreviousDefault    6000 non-null   int64 \n",
            " 3   FirstName          6000 non-null   object\n",
            " 4   LastName           6000 non-null   object\n",
            " 5   NumberPets         6000 non-null   int64 \n",
            " 6   PreviousAccounts   6000 non-null   int64 \n",
            " 7   ResidenceDuration  6000 non-null   int64 \n",
            " 8   Street             6000 non-null   object\n",
            " 9   LicensePlate       6000 non-null   object\n",
            " 10  BadCredit          6000 non-null   int64 \n",
            " 11  Amount             6000 non-null   int64 \n",
            " 12  Married            6000 non-null   int64 \n",
            " 13  Duration           6000 non-null   int64 \n",
            " 14  City               6000 non-null   object\n",
            " 15  Purpose            6000 non-null   object\n",
            " 16  DateOfBirth        6000 non-null   object\n",
            "dtypes: int64(8), object(9)\n",
            "memory usage: 797.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdiKKblCo53S"
      },
      "source": [
        "## 3.1: Baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSumAZUAo9O6"
      },
      "source": [
        "# TODO: Insert code here. Feel free to create additional code cells if necessary."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugyTS51Ko5vz"
      },
      "source": [
        "## 3.2: Feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "742aYkYbprVD"
      },
      "source": [
        "# TODO: Insert code here. Feel free to create additional code cells if necessary."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsdD0clko5pz"
      },
      "source": [
        "## 3.3: Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxX2ERqzpqxi"
      },
      "source": [
        "# TODO: Insert code here. Feel free to create additional code cells if necessary."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff4l2aNKo5fr"
      },
      "source": [
        "## 3.4: Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XaxtTWMpIpP"
      },
      "source": [
        "# TODO: Insert code here. Feel free to create additional code cells if necessary."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te9gGGLEpXRG"
      },
      "source": [
        "## 3.5: Performance estimation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV_35bEupbfs"
      },
      "source": [
        "# TODO: Insert code here. Feel free to create additional code cells if necessary."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPiErnUaTQSk"
      },
      "source": [
        "# Question 4: Uncle Steve's Wind Farm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzLLQCmKTk9E"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "\n",
        "Uncle Steve has invested in wind. He's built a BIG wind farm with a total of  700 turbines. He's been running the farm for a couple of years now and things are going well. He sells the power generated by the farm to the Kingston government and makes a tidy profit. And, of course, he has been gathering data about the turbines' operations.\n",
        "\n",
        "One area of concern, however, is the cost of maintenece. While the turbines are fairly robust, it seems like one breaks/fails every couple of days. When a turbine fails, it usually costs around \\$20,000 to repair it. Yikes!\n",
        "\n",
        "Currently, Uncle Steve is not doing any preventative maintenance. He just waits until a turbine fails, and then he fixes it. But Uncle Steve has recently learned that if he services a turbine *before* it fails, it will only cost around $2,000. \n",
        "\n",
        "Obviously, there is a potential to save a lot of money here. But first, Uncle Steve would need to figure out *which* turbines are about to fail. Uncle Steve being Uncle Steve, he wants to use ML to build a predictive maintenance model. The model will alert Uncle Steve to potential turbine failures before they happen, giving Uncle Steve a chance to perform an inspection on the turbine and then fix the turbine before it fails. Uncle Steve plans to run the model every morning. For all the turbines that the model predicts will fail, Uncle Steve will order an inspection (which cost a flat \\$500, no matter if the turbine was in good health or not; the \\$500 would not be part of the $2,000 service cost). For the rest of the turbines, Uncle Steve will do nothing.\n",
        "\n",
        "Uncle Steve has used the last few year's worth of operation data to build and assess a model to predict which turbines will fail on any given day. (The data includes useful features like sensor readings, power output, weather, and many more, but those are not important for now.) In fact, he didn't stop there: he built and assessed two models. One model uses using deep learning (in this case, RNNs), and the other uses random forests.\n",
        "\n",
        "He's tuned the bejeebers out of each model and is comfortable that he has found the best-performing version of each. Both models seem really good: both have accuracy scores > 99%. The RNN has better recall, but Uncle Steve is convinced that the random forest model will be better for him since it has better precision. Just to be sure, he has hired you to double check his calculations. \n",
        "\n",
        "**Your task**\n",
        "\n",
        " Which model will save Uncle Steve more money? Justify.\n",
        "\n",
        "\n",
        "In addition to the details above, here is the assessment of each model:\n",
        "\n",
        "- Confusion matrix for the random forest:\n",
        "\n",
        "|         | Predicted Fail           | Predicted No Fail  |\n",
        "| ------------- |------------| -----:|\n",
        "| **Actual Fail**      | 201 | 55 |\n",
        "| **Actual No Fail**   | 50 | 255195 |\n",
        "\n",
        "- Confusion matrix for the RNN:\n",
        "\n",
        "|         | Predicted Fail           | Predicted No Fail  |\n",
        "| ------------- |------------| -----:|\n",
        "| **Actual Fail**      | 226 | 30 |\n",
        "| **Actual No Fail**   | 1200 | 254045 |\n",
        "\n",
        "\n",
        "**Marking**\n",
        "\n",
        "- *Quality*. Response is well-justified and convincing. \n",
        "- *Style*. Response uses proper grammar, spelling, and punctuation. Response is clear and professional. Response is complete, but not overly-verbose. Response follows length guidelines.\n",
        "\n",
        "\n",
        "\n",
        "**Tips**\n",
        "\n",
        "- Figure out how much Uncle Steve is currently (i.e., without any predictive maintinance models) paying in maintenance costs.\n",
        "- Use the information provided above to create a cost matrix.\n",
        "- Use the cost matrix and the confusion matrices to determine the costs of each model.\n",
        "- The cost of an inspection is the same, no matter if the turbine is in good condition or is about to fail.\n",
        "- If the inspection determines that a turbine is about to fail, then it will be fixed right then and there for the additional fee.\n",
        "- For simplicity, assume the inspections are perfect: i.e., that inspecting a turbine will definitely catch any problems that might exist, and won't accidentally flag an otherwise-healthy turbine.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAf1SIeKTkfl"
      },
      "source": [
        "TODO: Delete this text and insert your answer here."
      ]
    }
  ]
}